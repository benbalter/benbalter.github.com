{"author":"Benjamin J. Balter","title":"Why You Should Always Write Software as Open Source, Even When It's Never Going to Be","excerpt":"When you are the only person that's ever going to see something, you're a lot more likely to \"just make it work. Therefore write open source\n","layout":"post","category":["Business","Technology"],"tags":[".govs","agile","code","contracting","development","enterprise","gov 2.0","government","IT","open source","procurement","proprietary"],"post_format":[],"url":"/2012/06/26/why-you-should-always-write-software-as-open-source/","date":"2012-06-26 00:00:00 -0400","id":"/2012/06/26/why-you-should-always-write-software-as-open-source","categories":["posts"],"next":"[![Dashboard all the things](http://ben.balter.com/wp-content/uploads/2012/07/dashboard-all-the-things-300x225.jpeg){.alignright}][1]\n\nI was recently asked how I would architect a personalized dashboard experience for visitors to a large, customer-facing website. My response? *I wouldn't.*\n\nA dashboard in a car or airplane makes sense. It's not as if I could click \"speedometer\" while driving or press the \"altimeter\" button while flying. I simply need everything at all times. But virtual interfaces don't have that same limitation. In fact they don't have any limitations. A dashboard can have as much information as the most ambitious engineer can dream — and that's exactly the problem.\n\nPut it in context: Google [recently announced the retirement of iGoogle][2], it's own personalized dashboard, and I second their nomination to induct dashboards into the #doingitwrong hall of fame, joining the likes of internet portals, splash pages, and well, basically anything involving ActiveX or Flash.\n\nDashboard were a fun user interface experiment. They really were, especially compared to the static pages they evolved from. That was the whole point of Web 2.0, wasn't it? Personalization? I mean, it was really cool to drag and drop widgets, and build a virtual command center to monitor my little corner of the internet, and that was fine when there wasn't much internet out there to monitor. But the web collectively hit a tipping point a few years back. From push notifications to always-on e-mail, in more ways than we imagine, we now bombard ourselves with more information that we can physically process at any given moment. [Quite literally][3].\n\nThink about it this way: when customers come to a website, they're not looking to solve 10 problems. They're looking to solve one. They don't want all the potentially relevant information thrown at them all at once; they just want what they need. And they want computers to make that determination for them. But hey, this isn't the first time those who predict our user experience needs have erred on the side of [moar is better][4].\n\nSo that's it? That's the end of simultaneous streams? [Far from it][5]. This once-disruptive technology now has a long journey down the Technology S Curve as it becomes the go-to solution for all the business intelligence and project analyst types that stumble across it, in other words, the late adopters.\n\nDon't get me wrong. I'm sure guilty of building [a dashboard][6] or [two][7] in my day. I'm not saying that they've never had a place. What I'm saying is that today, not even the most complex dashboard could give you an accurate snapshot of its genus's future. If not dashes, then what? Beyond turning everything into a ubiquitous search box (*a la* [gov.uk][8]), I'm far from for a UI/UX expert, but I tend to think that startups generally have a pretty good sense of what's next. They have to. If they don't get it right the first time around, they tend not to have a second try. So what do we see?\n\n* **Activity -** Social apps like Facebook, Twitter, Foursquare, even GitHub are all built around the concept of activity. Whether its a news feed, recent checkins, or even commit activity, the question I come with is \"what's going on?\" and it gets answered as in depth as I care to scroll through, not as in depth as an engineer arbitrarily decided I needed a few years back. It's linear. It's [inverted pyramid][9]. It's customized by whom or what I follow, not by what I add or (re)arrange.\n\n* **Minimal** – Productivity apps like Gmail, Google Reader, even dropbox don't summarize for me how many e-mails, unread posts, or free MB I have as soon as I log in, and with the exception of a few labs features here or there, don't even give me the option to have anything more than a bare-bones inbox, unread feed, or directory listing. In fact, GMail and Google Reader were recently criticized for [going a bit too far][10] in this direction. But the lesson is the same: just give me my stuff and get out of the way.\n\n* **Immediate** - Transactional apps, like Uber or Square focus on action, not the past (or even the present). When I open the Uber or square apps, I'm immediately presented with the ability to request a vehicle or swipe a card, not my top tasks, not an arbitrary array of options or metrics, not with recent news about the product or popular add-ons. The app simply stands at attention, awaiting orders. I actually had to dig a bit to find my transaction history and related business analytics, and I'd argue that's a really good thing.\n\nThink about the last time you've used a drag-and-drop dashboard: If you're like me, it's going to be either Google Analytics or WordPress, and if that's the case, it's simply known as *the screen you see after you log in, but before you can do what you need to do*. It's wasted pixels. It's cruft from a bygone era when clicks were expensive and developers were left wondering \"how can we fit more on a page\".\n\nOptions are a crutch. It's the natural tendency of any engineer to over engineer a system, and that tendency is even stronger in a risk-averse, top-down culture [like government][11]. But your job — as an engineer, as a product manager, as user — is to push back, to fight that urge, to make [decisions, not options][12]. Not convinced? That feature you can't [bring yourself to cut][13]? Expose it through your API and see how many users complain.\n\nIt's no longer a question of \"is this possible technologically?\". It's no longer a matter of \"can you expose me to that information 24/7?\". Ever since the advent of [Zombo com][14], the only limit is our imagination. We've figured out the hard stuff. It's not centralization and personalization. It's decentralization and interoperability. Simplicity is the new black.\n\n [1]: http://ben.balter.com/wp-content/uploads/2012/07/dashboard-all-the-things.jpeg\n [2]: http://googleblog.blogspot.com/2012/07/spring-cleaning-in-summer.html\n [3]: http://www.apple.com/iphone/features/retina-display.html\n [4]: http://www.pocket-lint.com/images/dynamic/NEWS-32125-b3a8b509bc5e3a074f7f240f57d71aa9.jpg\n [5]: http://www.informationweek.com/news/software/productivity_apps/240003296\n [6]: http://my.fcc.gov/\n [7]: http://codex.wordpress.org/Dashboard_Screen\n [8]: http://gov.uk\n [9]: http://en.wikipedia.org/wiki/Inverted_pyramid\n [10]: http://jonoscript.wordpress.com/2012/04/26/gmail-designer-arrogance-and-the-cult-of-minimalism/\n [11]: http://www.google.com/?q=dashboard+site:.gov\n [12]: http://wordpress.org/about/philosophy/\n [13]: https://github.com/blog/1091-spring-cleaning\n [14]: http://html5zombo.com/","previous":"<p><a href='http://www.governmentciomagazine.com'><img alt='' class='alignright' src='http://ben.balter.com/wp-content/uploads/2012/06/government-cio-magazine-june-2012.png' /></a>Despite increasing public support (as well as a number of executive mandates) publishing public data in a machine-readable format is not as simple as pressing the &#8220;publish&#8221; button. Why? Equally important as exposing the information itself is fostering a vibrant developer ecosystem around it. By making the publishing agency, not the public, responsible for making information immediately useful, government can lower the barriers associated with consuming its data and introduce additional citizen services at little to no cost to the agency.</p>\n\n<p><strong>1. Garbage in, garbage out.</strong> Good, clean data may be surprisingly difficult to come by, especially when working with government systems that have been coupled together over decades. Data standards and conventions change, mechanisms of data collection evolve, and the data itself may be interpreted differently as new policies are introduced. As a result consistent practices, like naming conventions or data formats, often go overlooked. Where practical, take steps to normalize the data prior to release, rather than pushing the responsibility off to be inefficiently repeated by each application individually.</p>\n\n<p><strong>2. Eat your own dog food.</strong> When organizations consume the products they create, they empirically deliver better, more reliable, and more innovative products. You&#8217;d never seek to buy a car from a dealer that&#8217;s never driven one, yet we often expect the public to build applications based on APIs (Application Programming Interfaces – how computers talk to one another) published by organizations that have never had to consume their own data. Rather than solving the same problem twice, start by exposing all relevant data through public APIs and then work backward to build internal applications that rely on those externally facing data feeds.</p>\n\n<p><strong>3. Data as a citizen service.</strong>It is tempting to try and meet open data benchmarks, at least on face, by publishing snapshots of large datasets. Yet multi-gigabyte database exports do little to encourage external development, especially when such data-dumps are delayed and infrequent. Imagine the usefulness of a Facebook feed that showed your friends&#8217; activity from last month. Datasets should be directly exposed so that the public has access to live, real-time data, either in its entirety, or through proper access controls. This not only allows agencies to deliver more useful information, but also reduces the need to store the same data in multiple formats and in multiple locations.</p>\n\n<p><strong>4. Curate discrete pieces of data.</strong>APIs are most useful when they do the heavy lifting for those consuming them, especially in terms of sifting through large amounts of data. In practical terms that means returning data to the most discrete level possible, be it a single row, rather than merely returning a subset of the dataset, or even returning a single cell. Seemingly obvious but often overlooked, a query for the broadband speeds at a given address, for example, should return only the data relating to that address, not the entire city or even state-wide dataset. By allowing developers to query the data directly that means they will need less development time on their end, and thus a higher likelihood that an application will be built.</p>\n\n<p><strong>5. Serve data in multiple formats.</strong>When providing a service, whether you are a waiter or a CIO, &#8220;the customer is always right.&#8221; In the context of APIs, that means you need to return the information in the developers&#8217; native tongue, not the server&#8217;s. For some languages, heavyweight methods like XML may make sense, for others, especially mobile applications, JSON or JSONP may be preferred. Be prepared to return data in multiple formats, even as those formats continue to evolve.</p>\n\n<p><strong>6. Minimize the handshake learning curve</strong>. Authentication may often be necessary, but the pain associated with it does not have to. Ensure that developers can easily register API keys, with minimal effort and without delay, and rely on common authentication frameworks (e.g., OAuth 2.0) to minimize the learning curve. Similarly, whenever practical, provide common API wrappers and other software development kits in multiple languages.</p>\n\n<p><strong>7. Encourage adoption through documentation.</strong> Often, the most overlooked aspect of exposing data is documentation. Describe the structure of the data fully, including how to interpret it, and ensure that any technical documentation such as lists of methods and sample code is both complete and accurate. The only thing worse than not having documentation is having wrong documentation. The best APIs even provide Wikis to allow developers to share tools and best practices with one another.</p>\n\n<p><strong>8. Follow industry standards and convention</strong>. Although APIs may just be beginning to take foothold in government, a set of best practices have quietly evolved in the private sector over the past several years. What may seem like small, technicalities, such as a truly RESTful API or using proper HTTP methods like GET, POST, PUT, and DELETE, for example, can mean the difference between useful and useless.</p>\n\n<p><strong>9. Bake in Analytics</strong>. When it comes to garnering support for future efforts, nothing can be more powerful than raw numbers. From the ground up, bake in analytics on both the application level (what applications are querying the API?), and across APIs on the dataset levels (what APIs are being used?). This will help establish data-driven priorities, such as what type of data may be a good candidate for future APIs.</p>\n\n<p><strong>10. Location, location, location.</strong>With the &#8220;consumerization&#8221; of mobile, datasets are increasingly becoming location based. It&#8217;s not what datasets are out there, but rather, what datasets are out there about my immediate world. Likewise, government datasets are increasingly about where, just as much as it is about what. It&#8217;s important that this reality be taken into account when building APIs by incorporating geospatial lookups within the API, such a relying on MongoDB or other location-aware data structures.</p>\n\n<p>Exposing data as a service is quickly becoming an industry-standard practice. Many popular startups owe their success to the vibrant app communities that surround them, grown simply by lifting some of the burden off of developers&#8217; shoulders. Government agencies may not yet be able to publish data with the mere click of a button, but when done right from the start, exposing additional data sources may be a more trivial task than many expect, and will in turn deliver value to citizens in ways today unimagined by agencies.</p>\n\n<p><em>This is an excerpt of an article originally published in the June 2012 issue of <a href='http://www.governmentciomagazine.com'>Government CIO Magazine</a>.</em> <strong><a href='http://www.governmentciomagazine.com/2012/06/ten-steps-publishing-government-data-developers-will-actually-use#blog-content'>Continue Reading →</a></strong></p>","content":"<p><a href='http://ben.balter.com/wp-content/uploads/2012/06/mike-holmes.jpeg'><img alt='Unsatisfied with your Contractor?' class='alignright' src='http://ben.balter.com/wp-content/uploads/2012/06/mike-holmes-203x300.jpeg' /></a></p>\n\n<p>There are two kinds of software: cludgy software and open source. Think about it logically. When you (or your organization) is the only person that&#8217;s ever going to see something, you&#8217;re a lot more likely to &#8220;just make it work.&#8221; After all, who would ever know? <sup id='fnref:1'><a href='#fn:1' rel='footnote'>1</a></sup></p>\n\n<p>But the same logic that applies to sweeping literal dirt under the rug doesn&#8217;t apply to writing code. Whereas a rug will always serve to cover the floor, applications evolve over time and code is often constantly reused and repurposed as customers&#8217; needs change. Simply put, it&#8217;s impossible to predict today where your code is going to be a year from now and it&#8217;s in your best interest to plan accordingly.</p>\n\n<p>Open source hedges this risk by distinguishing generic logic (say posting content online) from application-specific customization (say the use-case-specific presentation of that content). Yet when you&#8217;re writing with the intention of producing proprietary or one-off code, you do everything in one pass. The true challenge arises when the same problem emerges again in another department, another business unit, or more generally in an even slightly different context. You&#8217;re reinventing the wheel. You&#8217;re &#8220;open sourcing&#8221; (even if within your organization). The solution? Always assume your software is going to be open source, even if you know it&#8217;s never going to be, and here&#8217;s why:</p>\n\n<p><strong>Flexible from the start</strong> - Imagine you building a house and the contractor literally nails down all your furniture at the onset, saying you could always remove it before you sell. You&#8217;d almost certainly hire a new contractor. Even if you&#8217;re never going to sell the house, you may want to get a new couch, or at the very least change a room&#8217;s layout somewhere down the line. Yet software developers do it all the time. We custom build solutions, and then go back and abstract logic to &#8220;open source&#8221; it as needed. You&#8217;re doubling the effort. Keep logic separate from implementation-specific customization, and you&#8217;ll have a shared, portable solution from day one. Put another way, your business unit is no way special or unique. The same logic that presents updates about the latest line of widgets to your customers can also be used to update the same customer base about cogs and you should prepare for that potential synergy from day one, even if not immediately realized.</p>\n\n<p><strong>Modular by design</strong>- Distinguishing unrelated components encourages several coding best practices. In addition to introducing a modular design, meaning additional components could easily be added (or existing components removed) down the line, abstraction often yields objectively more stable and more readably maintainable code due to the abhorrence of the copy-and-paste effect. Put another way, you&#8217;re forced to build elegant solutions — the fact that others are not only going to see, but have to be able to use and adapt your code forces you to follow best-practices like name spacing, abstraction, and object oriented programming.</p>\n\n<p><strong>A message to your future self</strong> – Ever go back and look at old code, <a href='https://twitter.com/BenBalter/status/209356982983999488'>only to scratch your head</a> as to what&#8217;s going on? The same you that may be asking yourself what you were thinking when you got a tattoo five years back, is also going to be asking why you wrote that singleton function five years ago. Yet when you write open source, you mitigate that risk by explaining your code in such a way that others (including your future self) can understand it. In a world of system orientated architectures and ever-changing requirements, the chance that a software project is one-and-done is increasingly rare, not to mention the fact that by failing to properly document, you&#8217;re introducing a significant risk of vendor lock in. Your successor will thank you, and so will the person paying the bills.</p>\n\n<p>The reality of today&#8217;s business environment is that all software is inherently &#8220;open source&#8221;, even if the scope of the sharing is limited to an organization. Assume the software is open, needs to be modular, and will be repurposed, and you will save significant costs in the long run. And when you require the same of outside contractors, you get better, more flexible code, and offset the risks of vendor or technology lock in in the long run.</p>\n\n<p>Justice Brandeis is famous for noting that &#8220;sunlight is the best disinfectant.&#8221; Likewise, the transparency afforded by the open-source ethos produces <a href='http://www.coverity.com/library/pdf/coverity-scan-2011-open-source-integrity-report.pdf'>more reliable software</a> – so why not simply assume your code is going to be open source from the start?</p>\n<div class='footnotes'><hr /><ol><li id='fn:1'>\n<p>The same would apply when you&#8217;re buying software and the contractor is under the impression no one outside the organization will ever see the code, and more importantly, the code could never negatively impact the public&#8217;s perception of their overall work-product <span>5</span></p>\n<a href='#fnref:1' rev='footnote'>&#8617;</a></li></ol></div>"}